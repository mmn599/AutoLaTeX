{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing methods\n",
    "\n",
    "This is just a bunch of shit for going from CHORME data to inputs, as well as training models. You have to input the ways you want to clean the images and which model and whatnot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "import scipy\n",
    "import skimage.morphology\n",
    "import skimage.transform\n",
    "from sklearn.model_selection import train_test_split\n",
    "from io import StringIO\n",
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import csv\n",
    "import warnings\n",
    "from sklearn.externals import joblib\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def normalize_coordinates(coords, maintain_ar = False):\n",
    "    min_x = np.min(coords[:,0])\n",
    "    min_y = np.min(coords[:,1])\n",
    "    max_x = np.max(coords[:,0])\n",
    "    max_y = np.max(coords[:,1])\n",
    "    \n",
    "    normalized = coords.copy()\n",
    "    normalized[:,0] = normalized[:,0] - min_x\n",
    "    normalized[:,1] = normalized[:,1] - min_y\n",
    "    \n",
    "    return normalized\n",
    "\n",
    "def coords_to_image(coords, clean=True):\n",
    "    normalized = normalize_coordinates(coords)\n",
    "    \n",
    "    M = np.max(normalized[:,0]) + 1\n",
    "    N = np.max(normalized[:,1]) + 1\n",
    "    \n",
    "    image = np.zeros((M,N))\n",
    "        \n",
    "    for coord in normalized:\n",
    "        image[coord[0],coord[1]] = 1\n",
    "\n",
    "    return image.transpose((1,0))\n",
    "    \n",
    "def stroke_to_arr(stroke):\n",
    "    stroke = stroke.replace(',', '\\n')\n",
    "    stroke_IO = StringIO(stroke)\n",
    "    stroke_arr = np.loadtxt(stroke_IO)\n",
    "    return stroke_arr\n",
    "\n",
    "def parse_meta(inkml_file):\n",
    "    tree = ET.parse(inkml_file)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    annotation = root.find(\"{http://www.w3.org/2003/InkML}annotation\")\n",
    "    return annotation.text\n",
    "    \n",
    "def parse_traces(inkml_file):\n",
    "    tree = ET.parse(inkml_file)\n",
    "    root = tree.getroot()\n",
    "    traces = root.findall(\"{http://www.w3.org/2003/InkML}trace\")\n",
    "    d_traces = []\n",
    "    for trace in traces:\n",
    "        d_trace = stroke_to_arr(trace.text)\n",
    "        if(len(d_trace.shape)==1):\n",
    "            d_trace = d_trace.reshape(1,d_trace.shape[0])\n",
    "        d_traces.append(d_trace)\n",
    "    return np.array(d_traces)\n",
    "\n",
    "def inkml_to_image(inkml_file):\n",
    "    traces = parse_traces(inkml_file)\n",
    "    image_id = parse_meta(inkml_file)\n",
    "    coords = []\n",
    "    for trace in traces:\n",
    "        coords.extend(trace)\n",
    "    coords = np.array(coords)\n",
    "    return image_id, coords_to_image(coords,False) \n",
    "\n",
    "def image_to_input(image):\n",
    "    return image.flatten()\n",
    "\n",
    "def input_to_image(X):\n",
    "    return X.reshape(NORMALIZED_IMAGE_SHAPE)\n",
    "\n",
    "BAD_LABELS = [\" junk\", \"junk\"]\n",
    "REL_PATH = os.path.join(\".\",\"data\",\"isolatedTest2014\")\n",
    "TRUTH_FILE = os.path.join(REL_PATH, \"iso_GT.txt\")\n",
    "MODELS_PATH = './pickle_files/CHORME/models/model'\n",
    "DATA_PATH = './pickle_files/CHORME/data/'\n",
    "IMAGES_PATH = './pickle_files/CHORME/images/'\n",
    "ORIGINAL_IMAGES_LIST = './pickle_files/CHORME/static/image_list'\n",
    "GROUND_TRUTH_SYMBOLS_LIST = './pickle_files/CHORME/static/symbols_list'\n",
    "NORMALIZED_IMAGE_SHAPE = (50,50)\n",
    "\n",
    "def compute_everything(cleaning_func, model, version=None):\n",
    "    \n",
    "    # build cleaned_images list\n",
    "    original_images, ground_truth_symbols = get_static(remove_bad_labels=True)\n",
    "    cleaned_images = []\n",
    "    for image in tqdm(original_images):\n",
    "        cleaned_image = cleaning_func(image)\n",
    "        cleaned_images.append(cleaned_image)\n",
    "         \n",
    "    # build inputs: convert relevant images to inputs\n",
    "    X = []\n",
    "    y = []\n",
    "    for image,symbol in zip(cleaned_images, ground_truth_symbols):\n",
    "        input_image = image_to_input(image)\n",
    "        X.append(input_image)\n",
    "        y.append(symbol)\n",
    "        \n",
    "    # train model\n",
    "    if(model):\n",
    "        model.fit(X, y)\n",
    "    else:\n",
    "        model = MLPClassifier(verbose=verbose)\n",
    "        model.fit(X, y)\n",
    "\n",
    "    # store if there's a version associated with it\n",
    "    if(version):\n",
    "        store_everything(version, cleaned_images, X, y, model)\n",
    "\n",
    "    return cleaned_images, X, y, model\n",
    "\n",
    "def get_everything(version=1):\n",
    "    model = joblib.load(MODELS_PATH + str(version))\n",
    "    X = joblib.load(DATA_PATH + \"/X\" + str(version))\n",
    "    y = joblib.load(DATA_PATH + \"/y\" + str(version))\n",
    "    cleaned_images = joblib.load(IMAGES_PATH + \"/cleaned_images\" + str(version))\n",
    "    return cleaned_images, X, y, model\n",
    "\n",
    "def store_everything(version, cleaned_images, X, y, model):\n",
    "    joblib.dump(model, MODELS_PATH + str(version))\n",
    "    joblib.dump(X, DATA_PATH + \"/X\" + str(version))\n",
    "    joblib.dump(y, DATA_PATH + \"/y\" + str(version))\n",
    "    joblib.dump(cleaned_images, IMAGES_PATH + \"/cleaned_images\"  + str(version))\n",
    "    \n",
    "def build_static():\n",
    "    original_images = []\n",
    "    ground_truth_symbols = []\n",
    "    symbol_dict = {}\n",
    "    with open(TRUTH_FILE, \"rt\") as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=',')\n",
    "        for row in reader:\n",
    "            symbol_dict[str(row[0])] = row[1]\n",
    "    inkml_files = glob.glob(os.path.join(REL_PATH,\"*.inkml\"))\n",
    "    for inkml_file in tqdm(inkml_files):\n",
    "        image_id, image = inkml_to_image(inkml_file)\n",
    "        symbol = symbol_dict[str(image_id)] \n",
    "        original_images.append(image)\n",
    "        ground_truth_symbols.append(symbol)\n",
    "        \n",
    "    original_images = np.array(original_images)\n",
    "#     print(original_images[0].shape)\n",
    "#     print(original_images.shape)\n",
    "#     print(len(ground_truth_symbols))\n",
    "    joblib.dump(original_images, ORIGINAL_IMAGES_LIST)\n",
    "    joblib.dump(ground_truth_symbols, GROUND_TRUTH_SYMBOLS_LIST)\n",
    "#     original_images, ground_truth_symbols = get_static(True)\n",
    "#     print(original_images.shape)\n",
    "#     print(len(ground_truth_symbols))\n",
    "    \n",
    "    return original_images, ground_truth_symbols\n",
    "    \n",
    "    \n",
    "def get_static(remove_bad_labels = True):      \n",
    "    original_images = joblib.load(ORIGINAL_IMAGES_LIST) \n",
    "    ground_truth_symbols = joblib.load(GROUND_TRUTH_SYMBOLS_LIST)\n",
    "    \n",
    "    if(remove_bad_labels):\n",
    "        images = []\n",
    "        symbols = []\n",
    "        for image,symbol in zip(original_images,ground_truth_symbols):\n",
    "            if(symbol not in BAD_LABELS):\n",
    "                images.append(image)\n",
    "                symbols.append(symbol)\n",
    "        return np.array(images), symbols    \n",
    "    \n",
    "    return original_images, ground_truth_symbols\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different cleaning and model methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def clean_v1(image):\n",
    "    diff = 5\n",
    "    image = np.pad(image, diff, mode='constant', constant_values=(0,0))\n",
    "    image = skimage.transform.resize(image, NORMALIZED_IMAGE_SHAPE)\n",
    "    return image\n",
    "\n",
    "def clean_v2(image):\n",
    "    image = clean_v1(image)\n",
    "    image = np.where(image, 1, 0)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization and evaluation methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def visualize_everything(version):\n",
    "    print('Version: ' + str(version))\n",
    "    print('Loading model...')\n",
    "    cleaned_images, X, y, model = get_everything(version)\n",
    "    print('Accuracy over all data: ' + str(model.score(X,y)))\n",
    "    print('Loading truth...')\n",
    "    original_images, ground_truth_symbols = get_static(True)\n",
    "    predicted_symbols = model.predict(X)\n",
    "    visualize_images_and_symbols(original_images, cleaned_images, ground_truth_symbols, predicted_symbols)\n",
    "\n",
    "def make_predictions(model, X):\n",
    "    return model.predict(X)\n",
    "\n",
    "def visualize_images_and_symbols(images, cleaned_images, y_true, y_pred):\n",
    "    for original_image, cleaned_image, y, y_p in zip(images[0:20], cleaned_images[0:20], y_true[0:20], y_pred[0:20]):\n",
    "        print('Actual: ' + str(y) + \"   |   \" + \"Predicted: \" + str(y_p))\n",
    "#         plt.subplot(121)\n",
    "#         plt.title('Original: ' + str(original_image.shape))\n",
    "#         plt.axis('off')\n",
    "#         plt.imshow(original_image, cmap=\"Greys\")\n",
    "#         plt.subplot(122)\n",
    "        plt.title('Cleaned image')\n",
    "        plt.axis('off')\n",
    "        plt.imshow(cleaned_image, cmap=\"Greys\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cleaned_images, X, y, model = get_everything(version=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '10.gif'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-06062fff580d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'10.gif'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'float64'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclean_v1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage_to_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode)\u001b[0m\n\u001b[0;32m   2270\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2271\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2272\u001b[1;33m         \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2273\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2274\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '10.gif'"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "image = np.asarray(Image.open('10.gif'), 'float64')\n",
    "image = clean_v1(image)\n",
    "image = image_to_input(image)\n",
    "ypred = model.predict(image)\n",
    "print(ypred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
